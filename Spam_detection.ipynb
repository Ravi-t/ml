{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyME4mBDF0VH58x8kJElbmHD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravi-t/ml/blob/main/Spam_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing and Importing Dependencies**"
      ],
      "metadata": {
        "id": "Vx5-WaQiF6hg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATbFb929CIZg",
        "outputId": "3f0edbee-380b-4902-9bca-cd7e59c5163a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "m_gZdIGhCNnK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Variables**"
      ],
      "metadata": {
        "id": "IUx1hVoOGG-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "EPOCHS=10\n",
        "MAX_LEN=512\n",
        "BATCH_SIZE=16"
      ],
      "metadata": {
        "id": "qucZnnVmCQST"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading and Preprocessing Data**"
      ],
      "metadata": {
        "id": "g96eKsAdGj0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/animesharma3/SPAM-SMS-Detection/master/spam_sms_collection.csv')[['msg', 'spam']]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rYLkkvyJCUFz",
        "outputId": "e42112bb-b987-4513-ad16-4c38d741c87e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 msg  spam\n",
              "0  go jurong point crazy available bugis n great ...     0\n",
              "1                            ok lar joking wif u oni     0\n",
              "2  free entry wkly comp win fa cup final tkts st ...     1\n",
              "3                u dun say early hor u c already say     0\n",
              "4                nah think go usf life around though     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5200e9e-e4c0-4178-a8d8-a1e6bbf136c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>msg</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nah think go usf life around though</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5200e9e-e4c0-4178-a8d8-a1e6bbf136c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5200e9e-e4c0-4178-a8d8-a1e6bbf136c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5200e9e-e4c0-4178-a8d8-a1e6bbf136c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e6365f2-99d2-4d03-ac41-0ff008f53f56\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e6365f2-99d2-4d03-ac41-0ff008f53f56')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e6365f2-99d2-4d03-ac41-0ff008f53f56 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDUUD1xzCWbG",
        "outputId": "57ff66cc-d34b-4041-a535-203b4c4fb840"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SMSCollectionDataset(Dataset):\n",
        "    def __init__(self, spam, msgs, tokenizer, max_len):\n",
        "        self.msgs = msgs\n",
        "        self.spam = spam\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.msgs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        msg = str(self.msgs[i])\n",
        "        spam = self.spam[i]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            msg,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'msg': msg,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'spam': torch.tensor(spam, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "TzRK1d9MCY3C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    ds = SMSCollectionDataset(\n",
        "        spam=df['spam'].to_numpy(),\n",
        "        msgs=df['msg'].to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=4\n",
        "    )"
      ],
      "metadata": {
        "id": "mbcc6XE6CbqB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = tts(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "df_val, df_test = tts(\n",
        "    df_test,\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "df_train.shape, df_test.shape, df_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyhnsidiCd0Q",
        "outputId": "df77e0c3-588c-4ca3-932c-14ba2218e103"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4457, 2), (558, 2), (557, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        ""
      ],
      "metadata": {
        "id": "cpT_LRLACf_E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = next(iter(train_data_loader))\n",
        "d.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBZrK6_KCiFg",
        "outputId": "b78eb9ce-4890-4f0b-87db-863d2036fbf0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['msg', 'input_ids', 'attention_mask', 'spam'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d['input_ids'].shape, d['attention_mask'].shape, d['spam'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8Ko-cXRCkM3",
        "outputId": "1a3c83d4-aa2d-4d25-ff67-f40eed601798"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 512]), torch.Size([16, 512]), torch.Size([16]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building**"
      ],
      "metadata": {
        "id": "L3Aarn1eGylk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpamClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(SpamClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )[1]\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)"
      ],
      "metadata": {
        "id": "Fw4alxuMCmk6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SpamClassifier(n_classes=2)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "gXn9CSLLCogA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss, Optimizer and Scheduler**"
      ],
      "metadata": {
        "id": "Jb-g5cAaG4V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "k92eZE-kCrVO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids = d['input_ids'].to(device)\n",
        "# attention_mask = d['attention_mask'].to(device)\n",
        "# targets = d['spam'].to(device)\n",
        "\n",
        "# outputs = model(\n",
        "#     input_ids=input_ids,\n",
        "#     attention_mask=attention_mask\n",
        "# )\n",
        "# loss = loss_fn(outputs, targets)\n",
        "# loss"
      ],
      "metadata": {
        "id": "zMinqQfpCuFt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Model Function**"
      ],
      "metadata": {
        "id": "WHcVA9E6G9fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(\n",
        "    model,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    data_loader,\n",
        "    n_examples\n",
        "):\n",
        "    model = model.train() # Setting Model in training mode\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d['input_ids'].to(device) # [16, 512]\n",
        "        attention_mask = d['attention_mask'].to(device) # [16, 512]\n",
        "        targets = d['spam'].to(device) # [16]\n",
        "\n",
        "        # Forward Propogation\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        ) # [16, 3]\n",
        "\n",
        "        # Calculating Loss\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Backward Propogation\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Clipping Gradient (Exploding Gradient Problem)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad() # Resetting gradients\n",
        "\n",
        "    train_acc = correct_predictions.double() / n_examples\n",
        "    train_loss = np.mean(losses)\n",
        "\n",
        "    return train_acc, train_loss"
      ],
      "metadata": {
        "id": "rsITYtSvCznZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validating Model Function**"
      ],
      "metadata": {
        "id": "orAA847WHBWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(\n",
        "    model,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    data_loader,\n",
        "    n_examples\n",
        "):\n",
        "    model = model.eval() # Setting Model in evaluation mode\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d['input_ids'].to(device) # [16, 512]\n",
        "            attention_mask = d['attention_mask'].to(device) # [16, 512]\n",
        "            targets = d['spam'].to(device) # [16]\n",
        "\n",
        "            # Forward Propogation\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            ) # [16, 3]\n",
        "\n",
        "            # Calculating Loss\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    train_acc = correct_predictions.double() / n_examples\n",
        "    train_loss = np.mean(losses)\n",
        "\n",
        "    return train_acc, train_loss"
      ],
      "metadata": {
        "id": "gDEMlzijC2tP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Model**"
      ],
      "metadata": {
        "id": "XimVvDKMHE8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_acc, train_loss = train(\n",
        "        model,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        device,\n",
        "        train_data_loader,\n",
        "        len(df_train)\n",
        "    )\n",
        "\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = evaluate_model(\n",
        "        model,\n",
        "        loss_fn,\n",
        "        device,\n",
        "        val_data_loader,\n",
        "        len(df_val)\n",
        "    )\n",
        "\n",
        "    print(f'Validation loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "        best_accuracy = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR6AtE-TC69o",
        "outputId": "c346d099-873e-4a7a-9700-4cb79707bbe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the Model Performance**"
      ],
      "metadata": {
        "id": "HWEFxcSLHKlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = evaluate_model(\n",
        "    model,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    test_data_loader,\n",
        "    len(df_test)\n",
        ")\n",
        "test_acc.item()"
      ],
      "metadata": {
        "id": "vAt6E8cuC-F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "plt.plot(history['train_acc.cpu().numpy()'], label='train accuracy')\n",
        "plt.plot(history['val_acc.cpu().numpy()'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1])"
      ],
      "metadata": {
        "id": "a-Rqt5uSDAUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(\n",
        "    model, data_loader\n",
        "):\n",
        "    model = model.eval()\n",
        "\n",
        "    msgs = []\n",
        "    predictions = []\n",
        "    predictions_probs = []\n",
        "    real_values = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            msg = d['msg']\n",
        "            input_ids = d['input_ids'].to(device)\n",
        "            attention_masks = d['attention_mask'].to(device)\n",
        "            spam = d['spam'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_masks\n",
        "            )\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "            msgs.extend(msg)\n",
        "            predictions.extend(preds)\n",
        "            predictions_probs.extend(probs)\n",
        "            real_values.extend(spam)\n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    predictions_probs = torch.stack(predictions_probs).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "    return msgs, predictions, predictions_probs, real_values"
      ],
      "metadata": {
        "id": "fBE9D1YDDDMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_msgs, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "metadata": {
        "id": "EWw0boqKDFZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Final Classification Report**"
      ],
      "metadata": {
        "id": "m82NLSPLHP-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_classification_report(Y_test, Y_pred):\n",
        "    print('--------Classification Report---------\\n')\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    f1 = f1_score(Y_test, Y_pred)\n",
        "    precision = precision_score(Y_test, Y_pred)\n",
        "    recall = recall_score(Y_test, Y_pred)\n",
        "    roc_auc = roc_auc_score(Y_test, Y_pred)\n",
        "    metrices = [accuracy, f1, precision, recall, roc_auc]\n",
        "    scores = pd.DataFrame(pd.Series(metrices).values, index=['accuracy', 'f1-score', 'precision', 'recall', 'roc auc score'], columns=['score'])\n",
        "    print(scores)\n",
        "    print('\\n--------Plotting Confusion Matrix---------')\n",
        "    sns.heatmap(confusion_matrix(Y_test, Y_pred), annot=True, cmap='RdYlGn_r', annot_kws={'size': 16})\n",
        "    return scores"
      ],
      "metadata": {
        "id": "ONJqS56DDH07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "VAw5a6u0DJ7Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}